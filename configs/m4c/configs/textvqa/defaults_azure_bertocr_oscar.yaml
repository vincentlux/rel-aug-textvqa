includes:
- ./defaults.yaml

training:
  num_workers: 0
  mlflow: true
  batch_size: 32
  max_updates: 48000
  evaluation_interval: 1000

dataset_config:
  textvqa:
    use_images: false
    use_features: true
    max_features: 100
    zoo_requirements:
    - textvqa.defaults
    - textvqa.ocr_en
    features:
      train:
      - textvqa/defaults/features/open_images/detectron_attrs_max50_v0.lmdb,textvqa/ocr_azure/features/ocr_azure_frcn_features.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      val:
      - textvqa/defaults/features/open_images/detectron_attrs_max50_v0.lmdb,textvqa/ocr_azure/features/ocr_azure_frcn_features.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      test:
      - textvqa/defaults/features/open_images/detectron_attrs_max50_v0.lmdb,textvqa/ocr_azure/features/ocr_azure_frcn_features.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
    annotations:
      train:
      - textvqa/defaults/annotations/imdb_train_ocr_azure-clus-unsorted-v0.npy,textvqa/defaults/annotations/imdb_train_ocr_en-v0.npy
      val:
      - textvqa/defaults/annotations/imdb_val_ocr_azure-clus-unsorted-v0.npy,textvqa/defaults/annotations/imdb_val_ocr_en-v0.npy
    processors:
      context_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 200
      obj_text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 70
    use_ocr_word_position: true
    pos_emb_length: 20


model_config:
  m4c_oscar:
    oscar_path: "data/base-vg-labels/ep_107_1192087"
    from_pretrained: true
    mmt_arch: true # use previous architecture but oscar weights if from_pretrained=true
    use_txtocr_output: false
    num_hidden_layers: 4
    ocr:
      encode_concat: true
      remove_ocr_posemb: false
      text_embedding: bert
      mmt_in_dim: 3480  # 604 (PHOC) + 2048 (Faster R-CNN) + 60 (posemb) + 6 (oscar pos) + 768 (text)
      normalize_bert: false
    obj:
      mmt_in_dim: 2816  # 768 (TEXT) + 2048 (Faster R-CNN)
      normalize_bert: false

optimizer:
  params:
    eps: 1.0e-08
    lr: 1e-4
    weight_decay: 0.0
  type: Adam