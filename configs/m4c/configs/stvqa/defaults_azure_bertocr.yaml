
model_config:
  m4c:
    ocr:
      encode_concat: true
      remove_ocr_posemb: false
      text_embedding: bert
      mmt_in_dim: 3480  # 768 (TEXT, 300 for fasttext) + 604 (PHOC) + 2048 (Faster R-CNN) + 0 (all zeros; legacy)
      normalize_bert: false
    obj:
      mmt_in_dim: 2816  # 768 (TEXT) + 2048 (Faster R-CNN)
      remove_obj_txtemb: false
      normalize_bert: false
    losses:
    - type: m4c_decoding_bce_with_mask

dataset_config:
  stvqa:
    zoo_requirements:
    - stvqa.defaults
    - stvqa.ocr_en
    features:
      train:
      - stvqa/defaults/features/detectron_attrs_max50_v0.lmdb,stvqa/ocr_azure/features/ocr_azure_frcn_features_all.lmdb,stvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      val:
      - stvqa/defaults/features/detectron_attrs_max50_v0.lmdb,stvqa/ocr_azure/features/ocr_azure_frcn_features_all.lmdb,stvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      test:
      - stvqa/defaults/features/detectron_attrs_max50_v0.lmdb,stvqa/ocr_azure/features/ocr_azure_frcn_features_all.lmdb,stvqa/ocr_en/features/ocr_en_frcn_features.lmdb
    annotations:
      train:
      - stvqa/defaults/annotations/azure_st_subtrain-v0.npy,stvqa/defaults/annotations/imdb_subtrain-v0.npy
      val:
      - stvqa/defaults/annotations/azure_st_subval-v0.npy,stvqa/defaults/annotations/imdb_subval-v0.npy
      test:
      - stvqa/defaults/annotations/azure_st_subtest-v0.npy,stvqa/defaults/annotations/imdb_test_task3-v0.npy
    processors:
      text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 20
      answer_processor:
        type: m4c_answer
        params:
          vocab_file: stvqa/defaults/extras/vocabs/fixed_answer_vocab_stvqa_5k.txt
          preprocessor:
            type: simple_word
            params: {}
          context_preprocessor:
            type: simple_word
            params: {}
          max_length: 50
          max_copy_steps: 12
          num_answers: 10
      copy_processor:
        type: copy
        params:
          max_length: 100
      phoc_processor:
        type: phoc
        params:
          max_length: 50
      context_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 250
#      context_processor:
#        type: bert
#        params:
#          max_length: 50
#          model_file: wiki.en.bin
      ocr_token_processor:
        type: simple_word
        params: {}
      bbox_processor:
        type: bbox
        params:
          max_length: 50
      obj_text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 100
    return_features_info: true
    use_ocr: true
    use_ocr_info: true
    use_order_vectors: false
    use_ocr_word_position: true
    pos_emb_length: 20

optimizer:
  params:
    eps: 1.0e-08
    lr: 1e-4
    weight_decay: 0
  type: Adam

evaluation:
  metrics:
  - stvqa_accuracy
  - stvqa_anls

training:
    clip_norm_mode: all
    clip_gradients: true
    max_grad_l2_norm: 0.25
    lr_scheduler: true
    lr_steps:
    - 14000
    - 19000
    lr_ratio: 0.1
    use_warmup: true
    warmup_factor: 0.2
    warmup_iterations: 1000
    max_updates: 24000
    batch_size: 16
    num_workers: 0
    task_size_proportional_sampling: true
    early_stop:
      criteria: stvqa/stvqa_accuracy
      minimize: false
    tensorboard: false
    mlflow: true
    evaluation_interval: 10