{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade azure-cognitiveservices-vision-computervision\n",
    "\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import const\n",
    "import json\n",
    "\n",
    "subscription_key = const.AZURE_KEY\n",
    "endpoint = \"https://textvqa.cognitiveservices.azure.com/\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with handwritten text\n",
    "# remote_image_handw_text_url = \"https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/cognitive-services/Computer-vision/Images/readsample.jpg\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "# recognize_handw_results = computervision_client.read(remote_image_handw_text_url,  raw=True)\n",
    "\n",
    "def word2dic(w):\n",
    "    ret = {}\n",
    "    for att in w.__dict__.keys():\n",
    "        ret[att] = w.__dict__[att]\n",
    "    return ret\n",
    "\n",
    "def line2dic(l):\n",
    "    ret = {}\n",
    "    for att in l.__dict__.keys():\n",
    "        if att!=\"words\":\n",
    "            ret[att] = l.__dict__[att]\n",
    "        else:\n",
    "            ret[\"words\"] = []\n",
    "            for w in l.words:\n",
    "                ret[\"words\"].append(word2dic(w))\n",
    "    return ret\n",
    "\n",
    "def res2dic(res):\n",
    "    ret = {}\n",
    "    for att in res.__dict__.keys():\n",
    "        if att!=\"lines\":\n",
    "            ret[att] = res.__dict__[att]\n",
    "        else:\n",
    "            ret[\"lines\"] = []\n",
    "            for l in res.lines:\n",
    "                ret[\"lines\"].append(line2dic(l))\n",
    "    return ret  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,_,ls in os.walk(const.IMG_PATH):\n",
    "    pred_ls = ls\n",
    "\n",
    "error_f = open(\"./azocr_fail_imgs_retry.txt\",\"w\")\n",
    "err_cnt = 0\n",
    "OFFSET = 10\n",
    "\n",
    "for cnt, img in enumerate(pred_ls[OFFSET:]):\n",
    "    if img.endswith(\".json\"):\n",
    "        continue\n",
    "    print(cnt+OFFSET,len(pred_ls),err_cnt,img,end=\"\\r\")\n",
    "    pred_im_path = os.path.join(const.IMG_PATH,img)\n",
    "    try:\n",
    "        recognize_handw_results = computervision_client.read_in_stream(open(pred_im_path, 'rb'),raw=True)\n",
    "    except:\n",
    "        error_f.write(f\"{cnt}\\t{img}\\tIO-ERROR\\n\")\n",
    "        err_cnt+=1\n",
    "        continue\n",
    "    # Get the operation location (URL with an ID at the end) from the response\n",
    "    operation_location_remote = recognize_handw_results.headers[\"Operation-Location\"]\n",
    "    # Grab the ID from the URL\n",
    "    operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "    # Call the \"GET\" API and wait for it to retrieve the results \n",
    "    while True:\n",
    "        get_handw_text_results = computervision_client.get_read_result(operation_id)\n",
    "        if get_handw_text_results.status not in ['notStarted', 'running']:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "        #print(\"SLEPT!\")\n",
    "\n",
    "    # Print the detected text, line by line\n",
    "    if get_handw_text_results.status == OperationStatusCodes.succeeded:\n",
    "        out_f = open(os.path.join(const.AZURE_OCR_PATH,img.split(\".\")[0]+\".json\"),\"w\")\n",
    "        results = get_handw_text_results.analyze_result.read_results\n",
    "        if len(results)>1:\n",
    "            raise NotImplementedError\n",
    "        json.dump(res2dic(get_handw_text_results.analyze_result.read_results[0]),out_f)\n",
    "        out_f.close()\n",
    "        #print(outstr)\n",
    "        #print(\"SUCCEED!\", img)\n",
    "    else:\n",
    "        #print(\"WRONG!\", img)\n",
    "        error_f.write(f\"{cnt}\\t{img}\\tOP-ERROR\\n\")\n",
    "        err_cnt+=1\n",
    "\n",
    "print()\n",
    "print(\"DA CHENG GONG!\")\n",
    "error_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
